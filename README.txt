Для запуска системы необходимо выполнить следующие шаги:
1.	Установить Docker
2.	.В каталоге проекта необходимо выполнить команду “docker compose up -d –build” Проверить, создались контейнеры, можно в программе Docker Desktop.
3.	Поместить входные файлы, которые нужно записать в базу данных input_data.
4.	Перейти в браузере по адресу http://localhost:8080. Ввести в качестве пользователя и пароля “airflow”
5.	На открывшейся странице Airflow в списке DAG щелкнуть по строке “item_classification”
6.	Справа страницы найти кнопку “Trigger” и нажать на нее. Таким образом, запустится выполнение процесса ETL и обучение ML-модели.
7.	После успешного завершения всех задач они буду помечены зеленым маркером.В базе mydb.db появятся таблицы, а в папке output_data будет создан файл ProductsStats.csv. 
8.	В интерфейсе MLflow по адресу http://localhost:5001 отобразится обученная ML-модель (вкладка "Models") и проведенные тесты (вкладка "Experiments")
Если файлы были помещены в папку archive после обработки, то повторно они уже не обрабатываются (т.е. игнорируются) при последующих запусках ETL-процесса. Если требуется повторно загрузить файлы, то необходимо удалить их из папки archive.	
